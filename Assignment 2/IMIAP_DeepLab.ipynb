{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import PIL\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os"
      ],
      "metadata": {
        "id": "Ypof9uMrY72z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# TODO:\n",
        "# Load images and plot some samples\n",
        "# Apply transformations if necessary\n",
        "# Split data into train and validation sets\n",
        "# Apply data augmentation on train set if needed\n",
        "# Create dataloaders\n",
        "##########################################################\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = ...\n",
        "val_dataset = ...\n",
        "\n",
        "train_dataloader = ...\n",
        "val_dataloader = ..."
      ],
      "metadata": {
        "id": "RkbDhf6JKG75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYkiFaNLYFG7"
      },
      "outputs": [],
      "source": [
        "##########################################################\n",
        "# TODO\n",
        "# Compute Atrous/Dilated Convolution\n",
        "##########################################################\n",
        "\n",
        "\n",
        "class Atrous_Convolution(nn.Module):\n",
        "    def __init__(\n",
        "            self, input_channels, kernel_size, pad, dilation_rate,\n",
        "            output_channels=256):\n",
        "        super(Atrous_Convolution, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Encoder of DeepLabv3+\n",
        "class ASSP(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channles, out_channles):\n",
        "        \"\"\"Atrous Spatial Pyramid pooling layer\n",
        "        Args:\n",
        "            in_channles (int): No of input channel for Atrous_Convolution.\n",
        "            out_channles (int): No of output channel for Atrous_Convolution.\n",
        "        \"\"\"\n",
        "\n",
        "        ##########################################################\n",
        "        # TODO\n",
        "        # Complete ASSP module\n",
        "        ##########################################################\n",
        "\n",
        "\n",
        "        super(ASSP, self).__init__()\n",
        "        self.conv_1x1 = ...\n",
        "\n",
        "        self.conv_6x6 = ...\n",
        "\n",
        "        self.conv_12x12 = ...\n",
        "\n",
        "        self.conv_18x18 = ...\n",
        "\n",
        "        self.image_pool = ...\n",
        "\n",
        "        self.final_conv = ...\n",
        "    def forward(self, x):\n",
        "        pass"
      ],
      "metadata": {
        "id": "PWzHa_9fYUHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNet_50(nn.Module):\n",
        "    def __init__(self, output_layer=None):\n",
        "        super(ResNet_50, self).__init__()\n",
        "        self.pretrained = torchvision.models.resnet50(pretrained=True)\n",
        "        self.output_layer = output_layer\n",
        "\n",
        "        # Get the layer names\n",
        "        self.layers = list(self.pretrained._modules.keys())\n",
        "\n",
        "        # Find how many layers to keep\n",
        "        self.layer_count = 0\n",
        "        for l in self.layers:\n",
        "            if l != self.output_layer:\n",
        "                self.layer_count += 1\n",
        "            else:\n",
        "                break  # Stop when we reach the output layer\n",
        "\n",
        "        # Remove layers after the output layer\n",
        "        # We need to remove len(layers) - layer_count - 1 layers\n",
        "        for _ in range(len(self.layers) - self.layer_count - 1):\n",
        "            # Remove the last key in the layers list\n",
        "            self.pretrained._modules.pop(self.layers[-1])\n",
        "            # Update the layers list since we modified the _modules\n",
        "            self.layers.pop()\n",
        "\n",
        "        # Create sequential from the remaining MODULES (not keys)\n",
        "        self.net = nn.Sequential(*self.pretrained._modules.values())\n",
        "\n",
        "        # Freeze parameters (optional)\n",
        "        for param in self.net.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "0OPS5BS6YXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# TODO\n",
        "# Compute Deeplabv3Plus model\n",
        "##########################################################\n",
        "\n",
        "\n",
        "class Deeplabv3Plus(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "\n",
        "        super(Deeplabv3Plus, self).__init__()\n",
        "\n",
        "        self.backbone = ResNet_50(output_layer='layer3')\n",
        "\n",
        "        self.low_level_features = ResNet_50(output_layer='layer1')\n",
        "\n",
        "    def forward(self, x):\n",
        "       pass"
      ],
      "metadata": {
        "id": "U3YaaqWGYacG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# TODO\n",
        "# Complete DiceBCELoss and IOU\n",
        "##########################################################\n",
        "\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        Dice_BCE = ...\n",
        "\n",
        "        return Dice_BCE\n",
        "\n",
        "\n",
        "class IOU(nn.Module):\n",
        "\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(IOU, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        IoU = ...\n",
        "\n",
        "        return IoU"
      ],
      "metadata": {
        "id": "Pvw6opNKYq_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "ERccu89iPV_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 100\n",
        "NUM_WORKERS = 4\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "\n",
        "model = Deeplabv3Plus(num_classes=1).to(DEVICE)\n",
        "loss_fn = DiceBCELoss()\n",
        "iou_fn = IOU()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "train_iou = []\n",
        "train_loss = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    iterations = 0\n",
        "    iter_loss = 0.0\n",
        "    iter_iou = 0.0\n",
        "\n",
        "    batch_loop = tqdm(train_loader)\n",
        "    model.train()\n",
        "    for batch_idx,(data,targets) in enumerate(batch_loop):\n",
        "        ##########################################################\n",
        "        # TODO\n",
        "        ##########################################################\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}, Training loss: {round(train_loss[-1] , 3)}\")\n",
        "\n",
        "    checkpoint = {\n",
        "    \"state_dict\" : model.state_dict(),\n",
        "    \"optimizer\" : optimizer.state_dict()\n",
        "        }\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            ##########################################################\n",
        "            # TODO\n",
        "            ##########################################################\n",
        "\n",
        "\n",
        "    print(f\"Dice score: {dice_score/len(val_loader)}\")\n"
      ],
      "metadata": {
        "id": "9xC4zBcsY0aX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}